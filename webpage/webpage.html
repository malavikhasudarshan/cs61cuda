<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=MXVwpSGzOOhqOc5hUWJbBLizfYjsfH9XaeDpmRKYJN5bV0WvE1cEyAoIq5yYZlSc);.lst-kix_prr7w4h8iuza-8>li:before{content:"\0025a0   "}.lst-kix_prr7w4h8iuza-7>li:before{content:"\0025cb   "}.lst-kix_prr7w4h8iuza-5>li:before{content:"\0025a0   "}.lst-kix_c74fkax9potz-5>li:before{content:"\0025a0   "}.lst-kix_c74fkax9potz-6>li:before{content:"\0025cf   "}.lst-kix_prr7w4h8iuza-4>li:before{content:"\0025cb   "}.lst-kix_prr7w4h8iuza-6>li:before{content:"\0025cf   "}.lst-kix_c74fkax9potz-3>li:before{content:"\0025cf   "}.lst-kix_c74fkax9potz-4>li:before{content:"\0025cb   "}.lst-kix_c74fkax9potz-7>li:before{content:"\0025cb   "}.lst-kix_c74fkax9potz-8>li:before{content:"\0025a0   "}.lst-kix_prr7w4h8iuza-1>li:before{content:"\0025cb   "}.lst-kix_prr7w4h8iuza-2>li:before{content:"\0025a0   "}.lst-kix_prr7w4h8iuza-3>li:before{content:"\0025cf   "}.lst-kix_c74fkax9potz-0>li:before{content:"\0025cf   "}.lst-kix_c74fkax9potz-1>li:before{content:"\0025cb   "}.lst-kix_c74fkax9potz-2>li:before{content:"\0025a0   "}.lst-kix_prr7w4h8iuza-0>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-1>li{counter-increment:lst-ctn-kix_50byjh385c5u-1}ol.lst-kix_50byjh385c5u-5.start{counter-reset:lst-ctn-kix_50byjh385c5u-5 0}.lst-kix_q9183ttubf8d-0>li:before{content:"\0025cf   "}ul.lst-kix_f1el7cytdyma-3{list-style-type:none}ul.lst-kix_f1el7cytdyma-4{list-style-type:none}ul.lst-kix_f1el7cytdyma-5{list-style-type:none}ul.lst-kix_f1el7cytdyma-6{list-style-type:none}ul.lst-kix_f1el7cytdyma-0{list-style-type:none}ul.lst-kix_f1el7cytdyma-1{list-style-type:none}.lst-kix_q9183ttubf8d-6>li:before{content:"\0025cf   "}ul.lst-kix_f1el7cytdyma-2{list-style-type:none}.lst-kix_q9183ttubf8d-7>li:before{content:"\0025cb   "}ul.lst-kix_f1el7cytdyma-7{list-style-type:none}ul.lst-kix_f1el7cytdyma-8{list-style-type:none}.lst-kix_q9183ttubf8d-8>li:before{content:"\0025a0   "}.lst-kix_wleds9j3q5ju-0>li:before{content:"\0025cf   "}.lst-kix_q9183ttubf8d-1>li:before{content:"\0025cb   "}.lst-kix_q9183ttubf8d-3>li:before{content:"\0025cf   "}.lst-kix_wleds9j3q5ju-1>li:before{content:"\0025cb   "}ul.lst-kix_sz6pv5pfluna-7{list-style-type:none}.lst-kix_q9183ttubf8d-2>li:before{content:"\0025a0   "}ul.lst-kix_sz6pv5pfluna-8{list-style-type:none}ul.lst-kix_sz6pv5pfluna-5{list-style-type:none}.lst-kix_wleds9j3q5ju-3>li:before{content:"\0025cf   "}.lst-kix_wleds9j3q5ju-4>li:before{content:"\0025cb   "}ul.lst-kix_sz6pv5pfluna-6{list-style-type:none}ul.lst-kix_sz6pv5pfluna-3{list-style-type:none}.lst-kix_q9183ttubf8d-5>li:before{content:"\0025a0   "}ul.lst-kix_sz6pv5pfluna-4{list-style-type:none}ul.lst-kix_sz6pv5pfluna-1{list-style-type:none}.lst-kix_wleds9j3q5ju-2>li:before{content:"\0025a0   "}ul.lst-kix_sz6pv5pfluna-2{list-style-type:none}.lst-kix_q9183ttubf8d-4>li:before{content:"\0025cb   "}ul.lst-kix_sz6pv5pfluna-0{list-style-type:none}.lst-kix_wleds9j3q5ju-8>li:before{content:"\0025a0   "}.lst-kix_wleds9j3q5ju-6>li:before{content:"\0025cf   "}.lst-kix_d2o3xwciua08-4>li:before{content:"\0025cb   "}.lst-kix_d2o3xwciua08-2>li:before{content:"\0025a0   "}.lst-kix_d2o3xwciua08-0>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-8>li{counter-increment:lst-ctn-kix_50byjh385c5u-8}ul.lst-kix_3x14p7wxt6qa-7{list-style-type:none}.lst-kix_d2o3xwciua08-6>li:before{content:"\0025cf   "}ul.lst-kix_3x14p7wxt6qa-8{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-3{list-style-type:none}.lst-kix_d2o3xwciua08-8>li:before{content:"\0025a0   "}ul.lst-kix_3x14p7wxt6qa-4{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-5{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-6{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-0{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-1{list-style-type:none}ul.lst-kix_3x14p7wxt6qa-2{list-style-type:none}ul.lst-kix_5db9i5s60gje-8{list-style-type:none}.lst-kix_y5uh0mwr7j92-1>li:before{content:"\0025cb   "}ul.lst-kix_5db9i5s60gje-6{list-style-type:none}ul.lst-kix_5db9i5s60gje-7{list-style-type:none}ul.lst-kix_5db9i5s60gje-4{list-style-type:none}ul.lst-kix_5db9i5s60gje-5{list-style-type:none}ul.lst-kix_5db9i5s60gje-2{list-style-type:none}ul.lst-kix_5db9i5s60gje-3{list-style-type:none}ul.lst-kix_5db9i5s60gje-0{list-style-type:none}ul.lst-kix_5db9i5s60gje-1{list-style-type:none}.lst-kix_y5uh0mwr7j92-3>li:before{content:"\0025cf   "}ol.lst-kix_50byjh385c5u-8.start{counter-reset:lst-ctn-kix_50byjh385c5u-8 0}.lst-kix_3vihw8j2vdba-3>li:before{content:"\0025cf   "}.lst-kix_y5uh0mwr7j92-5>li:before{content:"\0025a0   "}.lst-kix_3vihw8j2vdba-1>li:before{content:"\0025cb   "}.lst-kix_y5uh0mwr7j92-7>li:before{content:"\0025cb   "}.lst-kix_50byjh385c5u-2>li{counter-increment:lst-ctn-kix_50byjh385c5u-2}.lst-kix_3vihw8j2vdba-7>li:before{content:"\0025cb   "}.lst-kix_3vihw8j2vdba-5>li:before{content:"\0025a0   "}.lst-kix_5db9i5s60gje-3>li:before{content:"\0025cf   "}.lst-kix_5taui8luwpv-8>li:before{content:"\0025a0   "}.lst-kix_50byjh385c5u-4>li{counter-increment:lst-ctn-kix_50byjh385c5u-4}.lst-kix_5db9i5s60gje-2>li:before{content:"\0025a0   "}ul.lst-kix_w1wkpvkjdp0z-8{list-style-type:none}.lst-kix_5taui8luwpv-2>li:before{content:"\0025a0   "}ul.lst-kix_w1wkpvkjdp0z-5{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-4{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-7{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-6{list-style-type:none}.lst-kix_5taui8luwpv-1>li:before{content:"\0025cb   "}ul.lst-kix_w1wkpvkjdp0z-1{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-0{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-3{list-style-type:none}ul.lst-kix_w1wkpvkjdp0z-2{list-style-type:none}.lst-kix_sz6pv5pfluna-0>li:before{content:"\0025cf   "}.lst-kix_sz6pv5pfluna-1>li:before{content:"\0025cb   "}ol.lst-kix_50byjh385c5u-1.start{counter-reset:lst-ctn-kix_50byjh385c5u-1 0}.lst-kix_f1el7cytdyma-6>li:before{content:"\0025cf   "}.lst-kix_sz6pv5pfluna-5>li:before{content:"\0025a0   "}ol.lst-kix_50byjh385c5u-7.start{counter-reset:lst-ctn-kix_50byjh385c5u-7 0}.lst-kix_f1el7cytdyma-3>li:before{content:"\0025cf   "}.lst-kix_f1el7cytdyma-7>li:before{content:"\0025cb   "}.lst-kix_sz6pv5pfluna-4>li:before{content:"\0025cb   "}.lst-kix_50byjh385c5u-6>li{counter-increment:lst-ctn-kix_50byjh385c5u-6}.lst-kix_5db9i5s60gje-7>li:before{content:"\0025cb   "}.lst-kix_5db9i5s60gje-6>li:before{content:"\0025cf   "}.lst-kix_q2sbc34b9ysv-0>li:before{content:"\0025cf   "}.lst-kix_f1el7cytdyma-2>li:before{content:"\0025a0   "}.lst-kix_q2sbc34b9ysv-4>li:before{content:"\0025cb   "}.lst-kix_3x14p7wxt6qa-2>li:before{content:"\0025a0   "}.lst-kix_q2sbc34b9ysv-3>li:before{content:"\0025cf   "}.lst-kix_3x14p7wxt6qa-1>li:before{content:"\0025cb   "}.lst-kix_q2sbc34b9ysv-8>li:before{content:"\0025a0   "}.lst-kix_q2sbc34b9ysv-7>li:before{content:"\0025cb   "}.lst-kix_u02faleibf2p-8>li:before{content:"\0025a0   "}.lst-kix_u02faleibf2p-5>li:before{content:"\0025a0   "}ol.lst-kix_50byjh385c5u-6.start{counter-reset:lst-ctn-kix_50byjh385c5u-6 0}ul.lst-kix_q9183ttubf8d-3{list-style-type:none}ul.lst-kix_q9183ttubf8d-2{list-style-type:none}.lst-kix_u02faleibf2p-0>li:before{content:"\0025cf   "}ul.lst-kix_q9183ttubf8d-1{list-style-type:none}ul.lst-kix_q9183ttubf8d-0{list-style-type:none}ul.lst-kix_q9183ttubf8d-7{list-style-type:none}ul.lst-kix_q9183ttubf8d-6{list-style-type:none}.lst-kix_u02faleibf2p-1>li:before{content:"\0025cb   "}ul.lst-kix_q9183ttubf8d-5{list-style-type:none}ul.lst-kix_q9183ttubf8d-4{list-style-type:none}.lst-kix_u02faleibf2p-4>li:before{content:"\0025cb   "}ul.lst-kix_q9183ttubf8d-8{list-style-type:none}.lst-kix_y5hpboojxrq7-4>li:before{content:"\0025cb   "}.lst-kix_wleds9j3q5ju-5>li:before{content:"\0025a0   "}.lst-kix_9cyp8qzhiam-2>li:before{content:"\0025a0   "}.lst-kix_y5hpboojxrq7-0>li:before{content:"\0025cf   "}ol.lst-kix_50byjh385c5u-0.start{counter-reset:lst-ctn-kix_50byjh385c5u-0 0}.lst-kix_y5hpboojxrq7-8>li:before{content:"\0025a0   "}.lst-kix_d2o3xwciua08-1>li:before{content:"\0025cb   "}.lst-kix_pm62bnpnrfb1-7>li:before{content:"\0025cb   "}ol.lst-kix_50byjh385c5u-3.start{counter-reset:lst-ctn-kix_50byjh385c5u-3 0}ul.lst-kix_c74fkax9potz-1{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-1{list-style-type:none}ul.lst-kix_c74fkax9potz-2{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-0{list-style-type:none}.lst-kix_cacb9gk4g194-4>li:before{content:"\0025cb   "}ul.lst-kix_c74fkax9potz-0{list-style-type:none}.lst-kix_pm62bnpnrfb1-3>li:before{content:"\0025cf   "}ul.lst-kix_c74fkax9potz-5{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-5{list-style-type:none}ul.lst-kix_c74fkax9potz-6{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-4{list-style-type:none}ul.lst-kix_c74fkax9potz-3{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-3{list-style-type:none}ul.lst-kix_c74fkax9potz-4{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-2{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-8{list-style-type:none}.lst-kix_cacb9gk4g194-0>li:before{content:"\0025cf   "}.lst-kix_cacb9gk4g194-8>li:before{content:"\0025a0   "}ul.lst-kix_c74fkax9potz-7{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-7{list-style-type:none}ul.lst-kix_c74fkax9potz-8{list-style-type:none}ul.lst-kix_y5uh0mwr7j92-6{list-style-type:none}.lst-kix_w1wkpvkjdp0z-6>li:before{content:"\0025cf   "}.lst-kix_d2o3xwciua08-5>li:before{content:"\0025a0   "}.lst-kix_w1wkpvkjdp0z-2>li:before{content:"\0025a0   "}.lst-kix_3x14p7wxt6qa-5>li:before{content:"\0025a0   "}.lst-kix_sz6pv5pfluna-8>li:before{content:"\0025a0   "}.lst-kix_y5uh0mwr7j92-2>li:before{content:"\0025a0   "}ul.lst-kix_pm62bnpnrfb1-8{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-7{list-style-type:none}.lst-kix_3vihw8j2vdba-2>li:before{content:"\0025a0   "}ul.lst-kix_pm62bnpnrfb1-6{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-5{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-4{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-3{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-2{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-1{list-style-type:none}ul.lst-kix_pm62bnpnrfb1-0{list-style-type:none}.lst-kix_y5uh0mwr7j92-6>li:before{content:"\0025cf   "}.lst-kix_3vihw8j2vdba-6>li:before{content:"\0025cf   "}.lst-kix_q8ivu5y5xq1n-7>li:before{content:"\0025cb   "}.lst-kix_50byjh385c5u-3>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-3,decimal) ". "}.lst-kix_50byjh385c5u-7>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-7,lower-latin) ". "}.lst-kix_9cyp8qzhiam-6>li:before{content:"\0025cf   "}ol.lst-kix_50byjh385c5u-2.start{counter-reset:lst-ctn-kix_50byjh385c5u-2 0}.lst-kix_q8ivu5y5xq1n-3>li:before{content:"\0025cf   "}.lst-kix_5taui8luwpv-5>li:before{content:"\0025a0   "}.lst-kix_n50pa8c09fq6-1>li:before{content:"\0025cb   "}.lst-kix_n50pa8c09fq6-0>li:before{content:"\0025cf   "}.lst-kix_n50pa8c09fq6-8>li:before{content:"\0025a0   "}.lst-kix_n50pa8c09fq6-7>li:before{content:"\0025cb   "}ol.lst-kix_50byjh385c5u-4.start{counter-reset:lst-ctn-kix_50byjh385c5u-4 0}.lst-kix_n50pa8c09fq6-2>li:before{content:"\0025a0   "}.lst-kix_n50pa8c09fq6-3>li:before{content:"\0025cf   "}.lst-kix_n50pa8c09fq6-4>li:before{content:"\0025cb   "}.lst-kix_n50pa8c09fq6-5>li:before{content:"\0025a0   "}.lst-kix_50byjh385c5u-3>li{counter-increment:lst-ctn-kix_50byjh385c5u-3}.lst-kix_n50pa8c09fq6-6>li:before{content:"\0025cf   "}ol.lst-kix_50byjh385c5u-4{list-style-type:none}ol.lst-kix_50byjh385c5u-5{list-style-type:none}ol.lst-kix_50byjh385c5u-6{list-style-type:none}ol.lst-kix_50byjh385c5u-7{list-style-type:none}ol.lst-kix_50byjh385c5u-8{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-0{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-1{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-2{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-3{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-4{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-5{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-6{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-7{list-style-type:none}ul.lst-kix_q8ivu5y5xq1n-8{list-style-type:none}ul.lst-kix_n50pa8c09fq6-7{list-style-type:none}ul.lst-kix_n50pa8c09fq6-6{list-style-type:none}ul.lst-kix_n50pa8c09fq6-5{list-style-type:none}ul.lst-kix_n50pa8c09fq6-4{list-style-type:none}ul.lst-kix_n50pa8c09fq6-8{list-style-type:none}.lst-kix_50byjh385c5u-7>li{counter-increment:lst-ctn-kix_50byjh385c5u-7}ol.lst-kix_50byjh385c5u-0{list-style-type:none}ol.lst-kix_50byjh385c5u-1{list-style-type:none}ol.lst-kix_50byjh385c5u-2{list-style-type:none}ol.lst-kix_50byjh385c5u-3{list-style-type:none}.lst-kix_y5hpboojxrq7-3>li:before{content:"\0025cf   "}.lst-kix_y5hpboojxrq7-5>li:before{content:"\0025a0   "}.lst-kix_9cyp8qzhiam-1>li:before{content:"\0025cb   "}.lst-kix_y5hpboojxrq7-7>li:before{content:"\0025cb   "}.lst-kix_50byjh385c5u-0>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-0,decimal) ". "}.lst-kix_50byjh385c5u-2>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-2,lower-roman) ". "}.lst-kix_y5hpboojxrq7-1>li:before{content:"\0025cb   "}.lst-kix_w1wkpvkjdp0z-7>li:before{content:"\0025cb   "}.lst-kix_pm62bnpnrfb1-8>li:before{content:"\0025a0   "}.lst-kix_pm62bnpnrfb1-6>li:before{content:"\0025cf   "}ul.lst-kix_y5hpboojxrq7-4{list-style-type:none}ul.lst-kix_y5hpboojxrq7-3{list-style-type:none}.lst-kix_cacb9gk4g194-5>li:before{content:"\0025a0   "}ul.lst-kix_y5hpboojxrq7-2{list-style-type:none}ul.lst-kix_y5hpboojxrq7-1{list-style-type:none}ul.lst-kix_y5hpboojxrq7-0{list-style-type:none}.lst-kix_cacb9gk4g194-3>li:before{content:"\0025cf   "}.lst-kix_cacb9gk4g194-7>li:before{content:"\0025cb   "}.lst-kix_pm62bnpnrfb1-0>li:before{content:"\0025cf   "}.lst-kix_pm62bnpnrfb1-4>li:before{content:"\0025cb   "}.lst-kix_cacb9gk4g194-1>li:before{content:"\0025cb   "}.lst-kix_3x14p7wxt6qa-8>li:before{content:"\0025a0   "}.lst-kix_w1wkpvkjdp0z-5>li:before{content:"\0025a0   "}.lst-kix_pm62bnpnrfb1-2>li:before{content:"\0025a0   "}.lst-kix_3x14p7wxt6qa-4>li:before{content:"\0025cb   "}.lst-kix_3x14p7wxt6qa-6>li:before{content:"\0025cf   "}.lst-kix_w1wkpvkjdp0z-3>li:before{content:"\0025cf   "}ul.lst-kix_y5hpboojxrq7-8{list-style-type:none}ul.lst-kix_y5hpboojxrq7-7{list-style-type:none}ul.lst-kix_y5hpboojxrq7-6{list-style-type:none}ul.lst-kix_y5hpboojxrq7-5{list-style-type:none}.lst-kix_w1wkpvkjdp0z-1>li:before{content:"\0025cb   "}.lst-kix_q8ivu5y5xq1n-0>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-8>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-8,lower-roman) ". "}.lst-kix_q8ivu5y5xq1n-8>li:before{content:"\0025a0   "}.lst-kix_9cyp8qzhiam-7>li:before{content:"\0025cb   "}.lst-kix_q8ivu5y5xq1n-6>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-4>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-4,lower-latin) ". "}.lst-kix_50byjh385c5u-6>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-6,decimal) ". "}.lst-kix_9cyp8qzhiam-5>li:before{content:"\0025a0   "}.lst-kix_5taui8luwpv-4>li:before{content:"\0025cb   "}.lst-kix_9cyp8qzhiam-3>li:before{content:"\0025cf   "}.lst-kix_q8ivu5y5xq1n-2>li:before{content:"\0025a0   "}.lst-kix_q8ivu5y5xq1n-4>li:before{content:"\0025cb   "}.lst-kix_5taui8luwpv-6>li:before{content:"\0025cf   "}.lst-kix_5db9i5s60gje-4>li:before{content:"\0025cb   "}.lst-kix_5db9i5s60gje-5>li:before{content:"\0025a0   "}ul.lst-kix_3vihw8j2vdba-0{list-style-type:none}.lst-kix_5taui8luwpv-7>li:before{content:"\0025cb   "}ul.lst-kix_3vihw8j2vdba-5{list-style-type:none}ul.lst-kix_3vihw8j2vdba-6{list-style-type:none}ul.lst-kix_3vihw8j2vdba-7{list-style-type:none}.lst-kix_5db9i5s60gje-1>li:before{content:"\0025cb   "}ul.lst-kix_3vihw8j2vdba-8{list-style-type:none}.lst-kix_5taui8luwpv-3>li:before{content:"\0025cf   "}ul.lst-kix_3vihw8j2vdba-1{list-style-type:none}ul.lst-kix_3vihw8j2vdba-2{list-style-type:none}ul.lst-kix_3vihw8j2vdba-3{list-style-type:none}ul.lst-kix_3vihw8j2vdba-4{list-style-type:none}.lst-kix_5taui8luwpv-0>li:before{content:"\0025cf   "}ul.lst-kix_u02faleibf2p-0{list-style-type:none}.lst-kix_5db9i5s60gje-0>li:before{content:"\0025cf   "}ul.lst-kix_9cyp8qzhiam-1{list-style-type:none}ul.lst-kix_9cyp8qzhiam-0{list-style-type:none}ul.lst-kix_9cyp8qzhiam-3{list-style-type:none}ul.lst-kix_9cyp8qzhiam-2{list-style-type:none}ul.lst-kix_9cyp8qzhiam-8{list-style-type:none}.lst-kix_sz6pv5pfluna-2>li:before{content:"\0025a0   "}ul.lst-kix_9cyp8qzhiam-5{list-style-type:none}ul.lst-kix_9cyp8qzhiam-4{list-style-type:none}ul.lst-kix_9cyp8qzhiam-7{list-style-type:none}ul.lst-kix_9cyp8qzhiam-6{list-style-type:none}.lst-kix_f1el7cytdyma-5>li:before{content:"\0025a0   "}.lst-kix_sz6pv5pfluna-6>li:before{content:"\0025cf   "}.lst-kix_sz6pv5pfluna-7>li:before{content:"\0025cb   "}.lst-kix_f1el7cytdyma-4>li:before{content:"\0025cb   "}.lst-kix_f1el7cytdyma-8>li:before{content:"\0025a0   "}.lst-kix_sz6pv5pfluna-3>li:before{content:"\0025cf   "}.lst-kix_5db9i5s60gje-8>li:before{content:"\0025a0   "}.lst-kix_f1el7cytdyma-0>li:before{content:"\0025cf   "}.lst-kix_q2sbc34b9ysv-1>li:before{content:"\0025cb   "}.lst-kix_f1el7cytdyma-1>li:before{content:"\0025cb   "}.lst-kix_q2sbc34b9ysv-2>li:before{content:"\0025a0   "}.lst-kix_3x14p7wxt6qa-0>li:before{content:"\0025cf   "}ul.lst-kix_q2sbc34b9ysv-3{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-2{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-1{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-0{list-style-type:none}.lst-kix_q2sbc34b9ysv-6>li:before{content:"\0025cf   "}ul.lst-kix_q2sbc34b9ysv-7{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-6{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-5{list-style-type:none}ul.lst-kix_q2sbc34b9ysv-4{list-style-type:none}.lst-kix_q2sbc34b9ysv-5>li:before{content:"\0025a0   "}ul.lst-kix_q2sbc34b9ysv-8{list-style-type:none}ul.lst-kix_wleds9j3q5ju-0{list-style-type:none}.lst-kix_u02faleibf2p-7>li:before{content:"\0025cb   "}ul.lst-kix_wleds9j3q5ju-2{list-style-type:none}ul.lst-kix_wleds9j3q5ju-1{list-style-type:none}ul.lst-kix_wleds9j3q5ju-4{list-style-type:none}ul.lst-kix_wleds9j3q5ju-3{list-style-type:none}.lst-kix_u02faleibf2p-6>li:before{content:"\0025cf   "}ul.lst-kix_wleds9j3q5ju-6{list-style-type:none}ul.lst-kix_wleds9j3q5ju-5{list-style-type:none}ul.lst-kix_wleds9j3q5ju-8{list-style-type:none}ul.lst-kix_u02faleibf2p-1{list-style-type:none}ul.lst-kix_d2o3xwciua08-2{list-style-type:none}ul.lst-kix_wleds9j3q5ju-7{list-style-type:none}ul.lst-kix_u02faleibf2p-2{list-style-type:none}ul.lst-kix_d2o3xwciua08-3{list-style-type:none}ul.lst-kix_u02faleibf2p-3{list-style-type:none}ul.lst-kix_d2o3xwciua08-4{list-style-type:none}ul.lst-kix_u02faleibf2p-4{list-style-type:none}ul.lst-kix_d2o3xwciua08-5{list-style-type:none}ul.lst-kix_u02faleibf2p-5{list-style-type:none}ul.lst-kix_u02faleibf2p-6{list-style-type:none}ul.lst-kix_u02faleibf2p-7{list-style-type:none}ul.lst-kix_d2o3xwciua08-0{list-style-type:none}ul.lst-kix_u02faleibf2p-8{list-style-type:none}ul.lst-kix_d2o3xwciua08-1{list-style-type:none}ul.lst-kix_prr7w4h8iuza-1{list-style-type:none}ul.lst-kix_prr7w4h8iuza-0{list-style-type:none}ul.lst-kix_d2o3xwciua08-6{list-style-type:none}.lst-kix_u02faleibf2p-2>li:before{content:"\0025a0   "}ul.lst-kix_d2o3xwciua08-7{list-style-type:none}ul.lst-kix_d2o3xwciua08-8{list-style-type:none}ul.lst-kix_prr7w4h8iuza-8{list-style-type:none}.lst-kix_u02faleibf2p-3>li:before{content:"\0025cf   "}ul.lst-kix_prr7w4h8iuza-7{list-style-type:none}ul.lst-kix_prr7w4h8iuza-6{list-style-type:none}ul.lst-kix_prr7w4h8iuza-5{list-style-type:none}ul.lst-kix_prr7w4h8iuza-4{list-style-type:none}ul.lst-kix_prr7w4h8iuza-3{list-style-type:none}ul.lst-kix_prr7w4h8iuza-2{list-style-type:none}.lst-kix_wleds9j3q5ju-7>li:before{content:"\0025cb   "}.lst-kix_y5hpboojxrq7-2>li:before{content:"\0025a0   "}.lst-kix_y5hpboojxrq7-6>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-1>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-1,lower-latin) ". "}.lst-kix_9cyp8qzhiam-0>li:before{content:"\0025cf   "}.lst-kix_d2o3xwciua08-3>li:before{content:"\0025cf   "}ul.lst-kix_n50pa8c09fq6-3{list-style-type:none}ul.lst-kix_n50pa8c09fq6-2{list-style-type:none}ul.lst-kix_n50pa8c09fq6-1{list-style-type:none}ul.lst-kix_n50pa8c09fq6-0{list-style-type:none}.lst-kix_w1wkpvkjdp0z-8>li:before{content:"\0025a0   "}.lst-kix_pm62bnpnrfb1-5>li:before{content:"\0025a0   "}.lst-kix_pm62bnpnrfb1-1>li:before{content:"\0025cb   "}.lst-kix_cacb9gk4g194-2>li:before{content:"\0025a0   "}ul.lst-kix_5taui8luwpv-7{list-style-type:none}ul.lst-kix_5taui8luwpv-8{list-style-type:none}.lst-kix_w1wkpvkjdp0z-4>li:before{content:"\0025cb   "}.lst-kix_3x14p7wxt6qa-3>li:before{content:"\0025cf   "}.lst-kix_3x14p7wxt6qa-7>li:before{content:"\0025cb   "}.lst-kix_d2o3xwciua08-7>li:before{content:"\0025cb   "}.lst-kix_w1wkpvkjdp0z-0>li:before{content:"\0025cf   "}.lst-kix_50byjh385c5u-0>li{counter-increment:lst-ctn-kix_50byjh385c5u-0}.lst-kix_cacb9gk4g194-6>li:before{content:"\0025cf   "}.lst-kix_y5uh0mwr7j92-0>li:before{content:"\0025cf   "}.lst-kix_y5uh0mwr7j92-4>li:before{content:"\0025cb   "}.lst-kix_q8ivu5y5xq1n-1>li:before{content:"\0025cb   "}ul.lst-kix_5taui8luwpv-5{list-style-type:none}.lst-kix_y5uh0mwr7j92-8>li:before{content:"\0025a0   "}ul.lst-kix_5taui8luwpv-6{list-style-type:none}ul.lst-kix_5taui8luwpv-3{list-style-type:none}.lst-kix_3vihw8j2vdba-4>li:before{content:"\0025cb   "}ul.lst-kix_5taui8luwpv-4{list-style-type:none}ul.lst-kix_5taui8luwpv-1{list-style-type:none}ul.lst-kix_5taui8luwpv-2{list-style-type:none}ul.lst-kix_5taui8luwpv-0{list-style-type:none}.lst-kix_3vihw8j2vdba-0>li:before{content:"\0025cf   "}ul.lst-kix_cacb9gk4g194-8{list-style-type:none}ul.lst-kix_cacb9gk4g194-7{list-style-type:none}ul.lst-kix_cacb9gk4g194-6{list-style-type:none}ul.lst-kix_cacb9gk4g194-5{list-style-type:none}.lst-kix_50byjh385c5u-5>li{counter-increment:lst-ctn-kix_50byjh385c5u-5}ul.lst-kix_cacb9gk4g194-4{list-style-type:none}ul.lst-kix_cacb9gk4g194-3{list-style-type:none}ul.lst-kix_cacb9gk4g194-2{list-style-type:none}ul.lst-kix_cacb9gk4g194-1{list-style-type:none}ul.lst-kix_cacb9gk4g194-0{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_9cyp8qzhiam-8>li:before{content:"\0025a0   "}.lst-kix_50byjh385c5u-5>li:before{content:"" counter(lst-ctn-kix_50byjh385c5u-5,lower-roman) ". "}.lst-kix_q8ivu5y5xq1n-5>li:before{content:"\0025a0   "}.lst-kix_3vihw8j2vdba-8>li:before{content:"\0025a0   "}.lst-kix_9cyp8qzhiam-4>li:before{content:"\0025cb   "}ol{margin:0;padding:0}table td,table th{padding:0}.c5{margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c22{padding-top:24pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c10{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Roboto Mono";font-style:normal}.c7{padding-top:18pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c2{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c24{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c12{text-decoration:none;vertical-align:baseline;font-style:normal}.c1{font-size:9pt;font-weight:400;font-family:"Roboto Mono"}.c13{font-size:13pt;font-family:"Arial"}.c15{padding:0;margin:0}.c21{margin-left:72pt;padding-left:0pt}.c14{margin-left:36pt;padding-left:0pt}.c18{font-size:17pt;font-family:"Arial"}.c8{font-weight:400;font-family:"Roboto Mono"}.c23{font-family:"Roboto Mono"}.c20{font-size:23pt}.c3{color:#188038}.c11{font-weight:700}.c16{font-size:11pt}.c6{height:11pt}.c19{font-family:"Arial"}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c24 doc-content"><h1 class="c22" id="h.naij31ue3p71"><span class="c2 c11 c19 c20">CS61Cuda Project: Matmul &amp; CUDA Fundamentals</span></h1><p class="c10"><span>Welcome to </span><span class="c11">CS61Cuda!!</span><span class="c0">&nbsp;This is a mini&#8209;project that introduces you to GPU programming with CUDA by building up to a fast matrix multiply. You&rsquo;ll start with a CPU reference, write your first CUDA kernels, learn to reason about grids/blocks/threads, and finally add simple vectorization (SIMD) on the GPU. An optional performance sandbox lets you explore optimizations for bragging rights.</span></p><p class="c10 c6"><span class="c0"></span></p><h2 class="c7" id="h.ncogedvx4iur"><span class="c2 c18 c11">Learning Goals</span></h2><ul class="c15 lst-kix_3vihw8j2vdba-0 start"><li class="c5 li-bullet-0"><span>Map data&#8209;parallel work to CUDA&rsquo;s </span><span class="c11">grid/block/thread</span><span class="c0">&nbsp;hierarchy.</span></li><li class="c5 li-bullet-0"><span>Practice </span><span class="c11">indexing</span><span>&nbsp;and </span><span class="c11">bounds checks</span><span class="c0">&nbsp;in 1D/2D.</span></li><li class="c5 li-bullet-0"><span>Understand </span><span class="c11">memory access patterns</span><span class="c0">&nbsp;(coalescing) and why they matter.</span></li><li class="c5 li-bullet-0"><span>See the benefits of </span><span class="c11">TLP</span><span>&nbsp;(thread&#8209;level parallelism) and </span><span class="c11">DLP</span><span class="c0">&nbsp;(data&#8209;level/SIMD) on the GPU.</span></li><li class="c5 li-bullet-0"><span>Read simple performance counters and reason about </span><span class="c11">memory&#8209; vs compute&#8209;bound</span><span class="c0">&nbsp;kernels.</span></li></ul><p class="c10 c6"><span class="c0"></span></p><h2 class="c7" id="h.1ony3v4xcg98"><span class="c2 c18 c11">Repo Layout &amp; What You Edit</span></h2><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">cs61cuda/</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">CMakeLists.txt</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">or</span><span class="c1">&nbsp;</span><span class="c1 c3">Makefile</span><span class="c1">&nbsp;</span><span class="c1 c3">(both</span><span class="c1">&nbsp;</span><span class="c1 c3">provided)</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">include/</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">matmul.h</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">shared</span><span class="c1">&nbsp;</span><span class="c1 c3">function</span><span class="c1">&nbsp;</span><span class="c1 c3">prototypes</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">src/</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">main.cpp</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">driver:</span><span class="c1">&nbsp;</span><span class="c1 c3">parses</span><span class="c1">&nbsp;</span><span class="c1 c3">flags,</span><span class="c1">&nbsp;</span><span class="c1 c3">allocs,</span><span class="c1">&nbsp;</span><span class="c1 c3">calls</span><span class="c1">&nbsp;</span><span class="c1 c3">your</span><span class="c1">&nbsp;</span><span class="c1 c3">code</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">cpu_baseline.cpp</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9999;&#65039;</span><span class="c1">&nbsp;</span><span class="c1 c3">Task</span><span class="c1">&nbsp;</span><span class="c1 c3">2:</span><span class="c1">&nbsp;</span><span class="c1 c3">implement</span><span class="c1">&nbsp;</span><span class="c1 c3">CPU</span><span class="c1">&nbsp;</span><span class="c1 c3">matmul</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">cuda_copy.cu</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9999;&#65039;</span><span class="c1">&nbsp;</span><span class="c1 c3">Task</span><span class="c1">&nbsp;</span><span class="c1 c3">1:</span><span class="c1">&nbsp;</span><span class="c1 c3">2D</span><span class="c1">&nbsp;</span><span class="c1 c3">copy</span><span class="c1">&nbsp;</span><span class="c1 c3">kernel</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">cuda_naive.cu</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9999;&#65039;</span><span class="c1">&nbsp;</span><span class="c1 c3">Task</span><span class="c1">&nbsp;</span><span class="c1 c3">3:</span><span class="c1">&nbsp;</span><span class="c1 c3">naive</span><span class="c1">&nbsp;</span><span class="c1 c3">CUDA</span><span class="c1">&nbsp;</span><span class="c1 c3">matmul</span><span class="c1">&nbsp;</span><span class="c1 c3">(1</span><span class="c1">&nbsp;</span><span class="c1 c3">output/thread)</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">cuda_simd.cu</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9999;&#65039;</span><span class="c1">&nbsp;</span><span class="c1 c3">Task</span><span class="c1">&nbsp;</span><span class="c1 c3">4:</span><span class="c1">&nbsp;</span><span class="c1 c3">vectorized</span><span class="c1">&nbsp;</span><span class="c1 c3">CUDA</span><span class="c1">&nbsp;</span><span class="c1 c3">matmul</span><span class="c1">&nbsp;</span><span class="c1 c3">(no</span><span class="c1">&nbsp;</span><span class="c1 c3">shared</span><span class="c1">&nbsp;</span><span class="c1 c3">mem)</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">utils.cu</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">timers,</span><span class="c1">&nbsp;</span><span class="c1 c3">error</span><span class="c1">&nbsp;</span><span class="c1 c3">checks,</span><span class="c1">&nbsp;</span><span class="c1 c3">random</span><span class="c1">&nbsp;</span><span class="c1 c3">init,</span><span class="c1">&nbsp;</span><span class="c1 c3">compare</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">check.cuh</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">CUDA</span><span class="c1">&nbsp;</span><span class="c1 c3">error</span><span class="c1">&nbsp;</span><span class="c1 c3">macros</span><span class="c1">&nbsp;</span><span class="c1 c3">(provided)</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">tests/</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">correctness_tests.py</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">local</span><span class="c1">&nbsp;</span><span class="c1 c3">correctness</span><span class="c1">&nbsp;</span><span class="c1 c3">checks</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">perf_runner.py</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">runs</span><span class="c1">&nbsp;</span><span class="c1 c3">sizes</span><span class="c1">&nbsp;</span><span class="c1 c3">&amp;</span><span class="c1">&nbsp;</span><span class="c1 c3">prints</span><span class="c1">&nbsp;</span><span class="c1 c3">throughput</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">data/</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">generate.py</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">makes</span><span class="c1">&nbsp;</span><span class="c1 c3">small</span><span class="c1">&nbsp;</span><span class="c1 c3">sample</span><span class="c1">&nbsp;</span><span class="c1 c3">matrices</span><span class="c1">&nbsp;</span><span class="c1 c3">(optional)</span></p><p class="c4"><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">scripts/</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9500;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">build.sh</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">nvcc</span><span class="c1">&nbsp;</span><span class="c1 c3">or</span><span class="c1">&nbsp;</span><span class="c1 c3">cmake</span><span class="c1">&nbsp;</span><span class="c1 c3">build</span><span class="c1">&nbsp;</span><span class="c1 c3">helper</span></p><p class="c4"><span class="c1 c3">&#9474;</span><span class="c1">&nbsp;</span><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">run_all.sh</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">runs</span><span class="c1">&nbsp;</span><span class="c1 c3">all</span><span class="c1">&nbsp;</span><span class="c1 c3">tasks</span><span class="c1">&nbsp;</span><span class="c1 c3">&amp;</span><span class="c1">&nbsp;</span><span class="c1 c3">tests</span></p><p class="c4"><span class="c1 c3">&#9492;&#9472;</span><span class="c1">&nbsp;</span><span class="c1 c3">README.md</span><span class="c1">&nbsp;</span><span class="c1 c3">#</span><span class="c1">&nbsp;</span><span class="c1 c3">quickstart</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span>&#60418;</span></p><p class="c10"><span class="c11">You will edit:</span><span>&nbsp;</span><span class="c8 c3">src/cpu_baseline.cpp</span><span>, </span><span class="c8 c3">src/cuda_copy.cu</span><span>, </span><span class="c8 c3">src/cuda_naive.cu</span><span>, </span><span class="c8 c3">src/cuda_simd.cu</span><span class="c0">.</span></p><p class="c10 c6"><span class="c0"></span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 482.67px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 482.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c11">Autograder policy.</span><span class="c0">&nbsp;We check correctness on hidden sizes, run times on a standard GPU, and basic style (clear bounds checks, no UB). We do not require a specific speedup, but we verify your kernels scale sensibly with size.</span></p><p class="c10"><span class="c11">Collaboration.</span><span class="c0">&nbsp;Discuss ideas high&#8209;level with peers; code must be your own. Cite any online sources you consulted.</span></p><p class="c10 c6"><span class="c0"></span></p><h2 class="c7" id="h.86rlcz2pvytg"><span class="c2 c18 c11">CUDA Primer (read first)</span></h2><ul class="c15 lst-kix_n50pa8c09fq6-0 start"><li class="c5 li-bullet-0"><span>A </span><span class="c11">kernel</span><span>&nbsp;is a C/C++ function annotated </span><span class="c8 c3">__global__</span><span>&nbsp;and launched with </span><span class="c8 c3">&lt;&lt;&lt;grid, block&gt;&gt;&gt;</span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span>Each launch creates a 2&#8209;D/3&#8209;D </span><span class="c11">grid</span><span>&nbsp;of </span><span class="c11">blocks</span><span>; each block contains many </span><span class="c11">threads</span><span class="c0">. Every thread runs the same kernel on different data.</span></li><li class="c5 li-bullet-0"><span>Built&#8209;in variables inside kernels: </span><span class="c8 c3">blockIdx.{x,y,z}</span><span>, </span><span class="c8 c3">threadIdx.{x,y,z}</span><span>, </span><span class="c8 c3">blockDim.{x,y,z}</span><span>, </span><span class="c8 c3">gridDim.{x,y,z}</span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span class="c0">Memory spaces:</span></li></ul><ul class="c15 lst-kix_n50pa8c09fq6-1 start"><li class="c10 c21 li-bullet-0"><span class="c11">Global</span><span class="c0">&nbsp;(device DRAM): large, high&#8209;latency; visible to all threads.</span></li><li class="c10 c21 li-bullet-0"><span class="c11">Shared</span><span class="c0">&nbsp;(on&#8209;chip, per&#8209;block): small, low&#8209;latency; visible to threads in the same block.</span></li><li class="c10 c21 li-bullet-0"><span class="c11">Registers</span><span class="c0">&nbsp;(per&#8209;thread): fastest.</span></li></ul><ul class="c15 lst-kix_n50pa8c09fq6-0"><li class="c5 li-bullet-0"><span class="c11">Memory coalescing:</span><span class="c0">&nbsp;threads in a warp should access consecutive addresses to combine loads/stores into few transactions.</span></li><li class="c5 li-bullet-0"><span class="c11">Synchronization:</span><span>&nbsp;</span><span class="c8 c3">__syncthreads()</span><span class="c0">&nbsp;is a barrier for all threads in a block (not across blocks).</span></li></ul><p class="c10"><span class="c0">You&rsquo;ll always (1) map data to threads, (2) ensure bounds checks, (3) choose grid/block sizes, and (4) verify results.</span></p><p class="c10 c6"><span class="c0"></span></p><h2 class="c7" id="h.zgmt231tcy9k"><span class="c2 c18 c11">Task 1 &mdash; Welcome to 61Cuda: 2D Copy Kernel (10 pts)</span></h2><h3 class="c17" id="h.85cuphttvae0"><span class="c2 c13 c11">Conceptual Overview</span></h3><p class="c10"><span class="c0">Warm up with indexing and coalesced global memory access. You&rsquo;ll copy a dense matrix from device input to device output using a 2D grid of 2D blocks, one element per thread.</span></p><h3 class="c17" id="h.2coqbkq4vmiq"><span class="c2 c13 c11">Data Flow</span></h3><ul class="c15 lst-kix_sz6pv5pfluna-0 start"><li class="c5 li-bullet-0"><span class="c11">Input:</span><span>&nbsp;</span><span class="c8 c3">in &isin; R^{rows&times;cols}</span><span>&nbsp;(row&#8209;major </span><span class="c8 c3">in[r*cols + c]</span><span>), allocated in </span><span class="c11">device</span><span class="c0">&nbsp;memory.</span></li><li class="c5 li-bullet-0"><span class="c11">Processing:</span><span>&nbsp;For each </span><span class="c8 c3">(r,c)</span><span>&nbsp;covered by a thread, read </span><span class="c8 c3">in[r,c]</span><span>&nbsp;and write it to </span><span class="c8 c3">out[r,c]</span><span class="c0">. Use 2&#8209;D indexing and guard against out&#8209;of&#8209;bounds.</span></li><li class="c5 li-bullet-0"><span class="c11">Output:</span><span>&nbsp;</span><span class="c8 c3">out &isin; R^{rows&times;cols}</span><span>&nbsp;identical to </span><span class="c8 c3">in</span><span class="c0">&nbsp;(device memory).</span></li></ul><h3 class="c17" id="h.unggy8qmxd85"><span class="c2 c13 c11">Your Task</span></h3><p class="c10"><span>Implement </span><span class="c8 c3">copy2D_kernel</span><span>&nbsp;and the host wrapper </span><span class="c12 c8 c3 c16">copy2D(...)</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&quot;check.cuh&quot;</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">__global__</span><span class="c1">&nbsp;</span><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">copy2D_kernel(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">__restrict__</span><span class="c1">&nbsp;</span><span class="c1 c3">in,</span></p><p class="c4"><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">__restrict__</span><span class="c1">&nbsp;</span><span class="c1 c3">out,</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">rows,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">cols)</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">compute</span><span class="c1">&nbsp;</span><span class="c1 c3">r,</span><span class="c1">&nbsp;</span><span class="c1 c3">c</span><span class="c1">&nbsp;</span><span class="c1 c3">using</span><span class="c1">&nbsp;</span><span class="c1 c3">blockIdx/threadIdx</span><span class="c1">&nbsp;</span><span class="c1 c3">and</span><span class="c1">&nbsp;</span><span class="c1 c3">blockDim</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">bounds</span><span class="c1">&nbsp;</span><span class="c1 c3">check:</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(r</span><span class="c1">&nbsp;</span><span class="c1 c3">&gt;=</span><span class="c1">&nbsp;</span><span class="c1 c3">rows</span><span class="c1">&nbsp;</span><span class="c1 c3">||</span><span class="c1">&nbsp;</span><span class="c1 c3">c</span><span class="c1">&nbsp;</span><span class="c1 c3">&gt;=</span><span class="c1">&nbsp;</span><span class="c1 c3">cols)</span><span class="c1">&nbsp;</span><span class="c1 c3">return;</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">copy</span><span class="c1">&nbsp;</span><span class="c1 c3">one</span><span class="c1">&nbsp;</span><span class="c1 c3">element</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">copy2D(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">d_in,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">d_out,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">rows,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">cols,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">block){</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">Suggest</span><span class="c1">&nbsp;</span><span class="c1 c3">block</span><span class="c1">&nbsp;</span><span class="c1 c3">=</span><span class="c1">&nbsp;</span><span class="c1 c3">(16,16,1)</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">grid((cols</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.x</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.x,</span></p><p class="c4"><span class="c1 c3">(rows</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.y);</span></p><p class="c4"><span class="c1 c3">copy2D_kernel&lt;&lt;&lt;grid,</span><span class="c1">&nbsp;</span><span class="c1 c3">block&gt;&gt;&gt;(d_in,</span><span class="c1">&nbsp;</span><span class="c1 c3">d_out,</span><span class="c1">&nbsp;</span><span class="c1 c3">rows,</span><span class="c1">&nbsp;</span><span class="c1 c3">cols);</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaGetLastError());</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaDeviceSynchronize());</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c0">&#60418;</span></p><p class="c10"><span class="c2 c11 c16 c19">Testing &amp; Tips</span></p><ul class="c15 lst-kix_w1wkpvkjdp0z-0 start"><li class="c5 li-bullet-0"><span>Prefer </span><span class="c8 c3">threadIdx.x</span><span>&nbsp;to index </span><span class="c11">columns</span><span class="c0">&nbsp;to encourage coalesced row&#8209;major accesses.</span></li><li class="c5 li-bullet-0"><span>Run: </span><span class="c8 c3">./build/cs61cuda --task=copy --M=64 --N=128 --verify</span><span class="c0">.</span></li></ul><p class="c10 c6"><span class="c0"></span></p><h2 class="c7" id="h.erqqyqpr05tg"><span class="c2 c18 c11">Task 2 &mdash; CPU Baseline Matmul (15 pts)</span></h2><h3 class="c17" id="h.yty6j9yjreab"><span class="c2 c13 c11">Conceptual Overview</span></h3><p class="c10"><span class="c0">Implement a correct triple&#8209;loop matrix multiply in row&#8209;major order. This is the correctness oracle for later tasks.</span></p><h3 class="c17" id="h.m15d0hlhvvx3"><span class="c2 c13 c11">Data Flow</span></h3><ul class="c15 lst-kix_q2sbc34b9ysv-0 start"><li class="c5 li-bullet-0"><span class="c11">Input:</span><span>&nbsp;</span><span class="c8 c3">A &isin; R^{M&times;K}</span><span>, </span><span class="c8 c3">B &isin; R^{K&times;N}</span><span class="c0">&nbsp;(host memory, row&#8209;major).</span></li><li class="c5 li-bullet-0"><span class="c11">Processing:</span><span>&nbsp;For every </span><span class="c8 c3">(i,j)</span><span>, compute </span><span class="c8 c3">C[i,j] = &Sigma;_{k=0..K-1} A[i,k] * B[k,j]</span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span class="c11">Output:</span><span>&nbsp;</span><span class="c8 c3">C &isin; R^{M&times;N}</span><span class="c0">&nbsp;(host memory).</span></li></ul><h3 class="c17" id="h.4c5bvnh219al"><span class="c2 c11 c13">Your Task</span></h3><p class="c10"><span>Fill </span><span class="c8 c3">mm_cpu(...)</span><span>&nbsp;in </span><span class="c8 c3">src/cpu_baseline.cpp</span><span class="c0">.</span></p><p class="c10"><span class="c11">Starter (skeleton) &mdash; </span><span class="c9 c3">src/cpu_baseline.cpp</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;cstddef&gt;</span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_cpu(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">A,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">B,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">C,</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">K){</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">triple</span><span class="c1">&nbsp;</span><span class="c1 c3">nested</span><span class="c1">&nbsp;</span><span class="c1 c3">loops</span><span class="c1">&nbsp;</span><span class="c1 c3">over</span><span class="c1">&nbsp;</span><span class="c1 c3">i</span><span class="c1">&nbsp;</span><span class="c1 c3">(rows</span><span class="c1">&nbsp;</span><span class="c1 c3">of</span><span class="c1">&nbsp;</span><span class="c1 c3">A),</span><span class="c1">&nbsp;</span><span class="c1 c3">j</span><span class="c1">&nbsp;</span><span class="c1 c3">(cols</span><span class="c1">&nbsp;</span><span class="c1 c3">of</span><span class="c1">&nbsp;</span><span class="c1 c3">B),</span><span class="c1">&nbsp;</span><span class="c1 c3">k</span><span class="c1">&nbsp;</span><span class="c1 c3">(shared</span><span class="c1">&nbsp;</span><span class="c1 c3">dim)</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">Use</span><span class="c1">&nbsp;</span><span class="c1 c3">row-major:</span><span class="c1">&nbsp;</span><span class="c1 c3">A[i*K</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">k],</span><span class="c1">&nbsp;</span><span class="c1 c3">B[k*N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">j],</span><span class="c1">&nbsp;</span><span class="c1 c3">C[i*N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">j]</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c10"><span>&#60418;</span></p><p class="c10"><span class="c11">Test</span><span class="c2 c11 c16 c19">ing &amp; Tips</span></p><ul class="c15 lst-kix_c74fkax9potz-0 start"><li class="c5 li-bullet-0"><span class="c0">Use small sizes first (e.g., 8&times;8&times;8). GPU results in later tasks are compared against this function with tolerance 1e&#8209;4.</span></li></ul><h2 class="c7" id="h.ayogalupbec5"><span class="c2 c18 c11">Task 3 &mdash; CUDA Naive Matmul (30 pts)</span></h2><h3 class="c17" id="h.qvz8q3klmqr"><span class="c2 c13 c11">Conceptual Overview</span></h3><p class="c10"><span>Parallelize Task 2 on the GPU: map each output element </span><span class="c8 c3">C[i,j]</span><span>&nbsp;to a single thread. This exposes </span><span class="c11">thread&#8209;level parallelism (TLP)</span><span class="c0">; performance is often limited by memory bandwidth.</span></p><h3 class="c17" id="h.kv65vbcz4ewh"><span class="c2 c13 c11">Data Flow</span></h3><ul class="c15 lst-kix_9cyp8qzhiam-0 start"><li class="c5 li-bullet-0"><span class="c11">Input:</span><span>&nbsp;</span><span class="c8 c3">A &isin; R^{M&times;K}</span><span>, </span><span class="c8 c3">B &isin; R^{K&times;N}</span><span class="c0">&nbsp;(device memory), populated from host.</span></li><li class="c5 li-bullet-0"><span class="c11">Processing:</span><span>&nbsp;Each thread computes one output </span><span class="c8 c3">C[i,j]</span><span>&nbsp;by streaming the </span><span class="c8 c3">k</span><span class="c0">&nbsp;dimension.</span></li><li class="c5 li-bullet-0"><span class="c11">Output:</span><span>&nbsp;</span><span class="c8 c3">C &isin; R^{M&times;N}</span><span class="c0">&nbsp;(device memory), copied back to host by the driver when verifying.</span></li></ul><h3 class="c17" id="h.wa28j5cv4i0b"><span class="c2 c13 c11">Your Task</span></h3><p class="c10"><span>Implement </span><span class="c8 c3">mm_naive_kernel</span><span>&nbsp;and the host launcher </span><span class="c8 c3">mm_naive(...)</span><span class="c0">.</span></p><p class="c10"><span class="c11">Starter (skeleton) &mdash; </span><span class="c3 c9">src/cuda_naive.cu</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&quot;check.cuh&quot;</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">__global__</span><span class="c1">&nbsp;</span><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_naive_kernel(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">__restrict__</span><span class="c1">&nbsp;</span><span class="c1 c3">A,</span></p><p class="c4"><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">__restrict__</span><span class="c1">&nbsp;</span><span class="c1 c3">B,</span></p><p class="c4"><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">__restrict__</span><span class="c1">&nbsp;</span><span class="c1 c3">C,</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">K){</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">compute</span><span class="c1">&nbsp;</span><span class="c1 c3">i</span><span class="c1">&nbsp;</span><span class="c1 c3">(row)</span><span class="c1">&nbsp;</span><span class="c1 c3">and</span><span class="c1">&nbsp;</span><span class="c1 c3">j</span><span class="c1">&nbsp;</span><span class="c1 c3">(col)</span><span class="c1">&nbsp;</span><span class="c1 c3">from</span><span class="c1">&nbsp;</span><span class="c1 c3">2D</span><span class="c1">&nbsp;</span><span class="c1 c3">grid/block</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">bounds</span><span class="c1">&nbsp;</span><span class="c1 c3">guard</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">TODO:</span><span class="c1">&nbsp;</span><span class="c1 c3">accumulate</span><span class="c1">&nbsp;</span><span class="c1 c3">over</span><span class="c1">&nbsp;</span><span class="c1 c3">k</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_naive(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">K,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">block){</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">grid((N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.x</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.x,</span></p><p class="c4"><span class="c1 c3">(M</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.y);</span></p><p class="c4"><span class="c1 c3">mm_naive_kernel&lt;&lt;&lt;grid,</span><span class="c1">&nbsp;</span><span class="c1 c3">block&gt;&gt;&gt;(dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">K);</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaGetLastError());</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaDeviceSynchronize());</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c10"><span class="c0">&#60418;</span></p><p class="c10"><span class="c2 c11 c16 c19">Notes on memory access</span></p><ul class="c15 lst-kix_3x14p7wxt6qa-0 start"><li class="c5 li-bullet-0"><span>Threads in a warp vary </span><span class="c8 c3">j</span><span>&nbsp;at fixed </span><span class="c8 c3">k</span><span>, so </span><span class="c8 c3">B[k*N + j]</span><span>&nbsp;is coalesced. Accesses to </span><span class="c8 c3">A[i*K + k]</span><span class="c0">&nbsp;replicate a single element per thread (cache helps).</span></li></ul><p class="c10"><span class="c11">Run</span><span>&nbsp;</span><span class="c12 c8 c3 c16">./build/cs61cuda --task=naive --M=512 --N=512 --K=512 --verify</span></p><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.lv0fccqly0iy"><span class="c2 c18 c11">Task 4 &mdash; CUDA SIMD Matmul (Vectorized, No Shared Memory) (30 pts)</span></h2><h3 class="c17" id="h.3l0d52ugbnah"><span class="c2 c13 c11">Conceptual Overview</span></h3><p class="c10"><span>Augment TLP with simple </span><span class="c11">data&#8209;level parallelism (DLP)</span><span>: each thread computes a short contiguous vector of outputs in a row using vector loads/stores (e.g., </span><span class="c8 c3">float4</span><span class="c0">). No shared memory yet.</span></p><h3 class="c17" id="h.xj8qkutktp9m"><span class="c2 c13 c11">Data Flow</span></h3><ul class="c15 lst-kix_wleds9j3q5ju-0 start"><li class="c5 li-bullet-0"><span class="c11">Input:</span><span>&nbsp;</span><span class="c8 c3">A &isin; R^{M&times;K}</span><span>, </span><span class="c8 c3">B &isin; R^{K&times;N}</span><span class="c0">&nbsp;(device).</span></li><li class="c5 li-bullet-0"><span class="c11">Processing:</span><span>&nbsp;A thread at </span><span class="c8 c3">(i, j0_group)</span><span>&nbsp;produces </span><span class="c8 c3">V</span><span>&nbsp;outputs </span><span class="c8 c3">C[i, j0..j0+V-1]</span><span>. Inner loop streams over </span><span class="c8 c3">k</span><span>, reading one scalar </span><span class="c8 c3">A[i,k]</span><span>&nbsp;and a vector of </span><span class="c8 c3">V</span><span>&nbsp;neighbors from row </span><span class="c8 c3">B[k, :]</span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span class="c11">Output:</span><span>&nbsp;</span><span class="c8 c3">C &isin; R^{M&times;N}</span><span class="c0">&nbsp;(device).</span></li></ul><h3 class="c17" id="h.8ezt534sonpz"><span class="c2 c13 c11">Your Task</span></h3><p class="c10"><span>Implement </span><span class="c8 c3">mm_simd_kernel&lt;V&gt;()</span><span>&nbsp;and its launcher. Default </span><span class="c8 c3">V=4</span><span>; handle tails where </span><span class="c8 c3">N % V &ne; 0</span><span class="c0">.</span></p><p class="c10"><span class="c11">Starter (skeleton) &mdash; </span><span class="c9 c3">src/cuda_simd.cu</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c12 c1 c3">#include &quot;check.cuh&quot;</span></p><p class="c4 c6"><span class="c12 c1 c3"></span></p><p class="c4"><span class="c12 c1 c3">template&lt;int V&gt;</span></p><p class="c4"><span class="c12 c1 c3">__global__ void mm_simd_kernel(const float* __restrict__ A,</span></p><p class="c4"><span class="c12 c1 c3">const float* __restrict__ B,</span></p><p class="c4"><span class="c12 c1 c3">float* __restrict__ C,</span></p><p class="c4"><span class="c12 c1 c3">int M, int N, int K){</span></p><p class="c4"><span class="c12 c1 c3">// TODO: compute i (row) and j0 (first column of this thread&#39;s vector)</span></p><p class="c4"><span class="c12 c1 c3">// TODO: maintain acc[V] and handle aligned vs tail paths</span></p><p class="c4"><span class="c1 c3 c12">}</span></p><p class="c4 c6"><span class="c12 c1 c3"></span></p><p class="c4"><span class="c12 c1 c3">void mm_simd(const float* dA, const float* dB, float* dC,</span></p><p class="c4"><span class="c12 c1 c3">int M, int N, int K, int vec, dim3 block){</span></p><p class="c4"><span class="c12 c1 c3">// TODO: call specialized kernel for vec==4, else fall back</span></p><p class="c4"><span class="c12 c1 c3">}</span></p><p class="c4 c6"><span class="c12 c1 c3"></span></p><p class="c10"><span>&#60418;</span></p><p class="c10"><span class="c11">Run</span><span>&nbsp;</span><span class="c12 c8 c3 c16">./build/cs61cuda --task=simd --M=1024 --N=1024 --K=1024 --vec=4 --verify</span></p><p class="c10"><span class="c2 c11 c16 c19">Discussion prompts</span></p><ul class="c15 lst-kix_cacb9gk4g194-0 start"><li class="c5 li-bullet-0"><span>Why does vectorizing along columns improve coalescing for loads from </span><span class="c3 c8">B</span><span>&nbsp;and stores to </span><span class="c8 c3">C</span><span class="c0">?</span></li><li class="c5 li-bullet-0"><span class="c0">What changes would shared&#8209;memory tiling introduce (Task 5 EC)?</span></li></ul><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.nluym1yc8qbd"><span class="c2 c18 c11">Task 5 &mdash; (Optional) Performance Engineering (15 EC)</span></h2><p class="c10"><span>Make it </span><span class="c11">faster</span><span class="c0">. Ideas:</span></p><ul class="c15 lst-kix_pm62bnpnrfb1-0 start"><li class="c5 li-bullet-0"><span class="c11">Shared&#8209;memory tiling</span><span class="c0">&nbsp;(classic 16&times;16 or 32&times;32 tiles).</span></li><li class="c5 li-bullet-0"><span class="c11">Register tiling</span><span>: each thread computes a small </span><span class="c8 c3">r&times;c</span><span class="c0">&nbsp;tile.</span></li><li class="c5 li-bullet-0"><span class="c11">Loop unrolling &amp; </span><span class="c3 c11 c23">#pragma unroll</span><span>&nbsp;for </span><span class="c8 c3">k</span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span class="c11">Occupancy tuning</span><span>: vary </span><span class="c8 c3">blockDim</span><span class="c0">&nbsp;to trade registers vs parallelism.</span></li><li class="c5 li-bullet-0"><span class="c11">Mixed precision</span><span>: keep FP32 accumulate but try </span><span class="c8 c3">__half</span><span class="c0">&nbsp;inputs (only if you also keep a FP32 correctness path for grading).</span></li><li class="c5 li-bullet-0"><span class="c11">Software prefetch</span><span>: read the next </span><span class="c8 c3">k</span><span class="c0">&nbsp;slice early.</span></li></ul><p class="c10"><span>We&rsquo;ll publish a lightweight leaderboard (GFLOP/s). Please write a short </span><span class="c11">README-perf.md</span><span class="c0">&nbsp;describing what you tried and why it helped (or didn&rsquo;t)</span></p><p class="c4"><span class="c2 c11 c16 c19">Command&#8209;Line Interface (Driver)</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">./cs61cuda</span><span class="c1">&nbsp;</span><span class="c1 c3">--task={copy|cpu|naive|simd}</span></p><p class="c4"><span class="c1 c3">--M=1024</span><span class="c1">&nbsp;</span><span class="c1 c3">--N=1024</span><span class="c1">&nbsp;</span><span class="c1 c3">--K=1024</span></p><p class="c4"><span class="c1 c3">--block=16</span><span class="c1">&nbsp;</span><span class="c1 c3">--vec=4</span><span class="c1">&nbsp;</span><span class="c1 c3">--repeat=10</span><span class="c1">&nbsp;</span><span class="c1 c3">--verify</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c0">&#60418;</span></p><ul class="c15 lst-kix_q8ivu5y5xq1n-0 start"><li class="c4 c14 li-bullet-0"><span class="c8 c3">--task=copy</span><span>&nbsp;ignores </span><span class="c8 c3">K</span><span class="c0">.</span></li><li class="c4 c14 li-bullet-0"><span class="c8 c3">--vec</span><span class="c0">&nbsp;controls SIMD width in Task 4; grader uses 4.</span></li><li class="c4 c14 li-bullet-0"><span class="c8 c3">--verify</span><span>&nbsp;runs </span><span class="c8 c3">mm_cpu</span><span class="c0">&nbsp;then compares results (L2 relative error &le; 1e-4).</span></li></ul><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.eb4faa61iwns"><span class="c2 c18 c11">Correctness &amp; Floating&#8209;Point Notes</span></h2><ul class="c15 lst-kix_u02faleibf2p-0 start"><li class="c5 li-bullet-0"><span>We compare with a small absolute+relative tolerance (</span><span class="c8 c3">1e-4</span><span class="c0">).</span></li><li class="c5 li-bullet-0"><span>Random inputs in </span><span class="c8 c3">[-1, 1]</span><span class="c0">&nbsp;with fixed seed.</span></li><li class="c5 li-bullet-0"><span>Your GPU kernels must </span><span class="c11">not</span><span>&nbsp;read/write out of bounds; failing </span><span class="c8 c3">cuda-memcheck</span><span class="c0">&nbsp;is an automatic zero for that test.</span></li></ul><hr><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.1yg0agcpjhoz"><span class="c2 c11 c18">Debugging Checklist</span></h2><ul class="c15 lst-kix_prr7w4h8iuza-0 start"><li class="c5 li-bullet-0"><span class="c0">After each kernel launch:</span></li></ul><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">cudaDeviceSynchronize();</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaGetLastError());</span></p><p class="c4 c6"><span class="c1 c2"></span></p><ul class="c15 lst-kix_q9183ttubf8d-0 start"><li class="c4 c14 li-bullet-0"><span>&#60418;Use </span><span class="c8 c3">printf</span><span>&nbsp;inside kernels </span><span class="c11">sparingly</span><span class="c0">&nbsp;on tiny sizes.</span></li><li class="c4 c14 li-bullet-0"><span>Try </span><span class="c8 c3">cuda-memcheck</span><span class="c0">&nbsp;for invalid addresses / race conditions.</span></li><li class="c4 c14 li-bullet-0"><span>Start small (e.g., </span><span class="c8 c3">M=N=K=8</span><span class="c0">) then scale.</span></li></ul><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.bzb8canm1vmv"><span class="c2 c18 c11">Style &amp; Submission</span></h2><ul class="c15 lst-kix_d2o3xwciua08-0 start"><li class="c5 li-bullet-0"><span>Clear variable names (</span><span class="c8 c3">i,j,k</span><span>, </span><span class="c8 c3">M,N,K</span><span class="c0">).</span></li><li class="c5 li-bullet-0"><span class="c0">Comments: what the mapping is, what each thread computes, any assumptions.</span></li><li class="c5 li-bullet-0"><span class="c0">No undefined behavior (no out&#8209;of&#8209;bounds pointer math, no aliasing shenanigans).</span></li><li class="c5 li-bullet-0"><span>Submit your edited </span><span class="c8 c3">.cpp/.cu</span><span>&nbsp;files and </span><span class="c11">README.md</span><span class="c0">&nbsp;answering the reflection prompts below.</span></li></ul><h3 class="c17" id="h.gdckqider48f"><span class="c2 c13 c11">Reflection (graded in Task 5 rubric even if you skip perf EC)</span></h3><ol class="c15 lst-kix_50byjh385c5u-0 start" start="1"><li class="c5 li-bullet-0"><span class="c0">Where is your naive kernel memory&#8209;bound? Which array dominates traffic and why?</span></li><li class="c5 li-bullet-0"><span class="c0">Why does vectorizing along columns improve coalescing? What&rsquo;s the trade&#8209;off?</span></li><li class="c5 li-bullet-0"><span class="c0">What would shared&#8209;memory tiling change about the access pattern?</span></li></ol><hr><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.hx8aevkxnb0r"><span class="c2 c18 c11">Reference: Shapes &amp; Indexing</span></h2><p class="c10"><span class="c0">Row&#8209;major:</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">A:</span><span class="c1">&nbsp;</span><span class="c1 c3">MxK</span><span class="c1">&nbsp;</span><span class="c1 c3">&rarr;</span><span class="c1">&nbsp;</span><span class="c1 c3">A[i*K</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">k]</span></p><p class="c4"><span class="c1 c3">B:</span><span class="c1">&nbsp;</span><span class="c1 c3">KxN</span><span class="c1">&nbsp;</span><span class="c1 c3">&rarr;</span><span class="c1">&nbsp;</span><span class="c1 c3">B[k*N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">j]</span></p><p class="c4"><span class="c1 c3">C:</span><span class="c1">&nbsp;</span><span class="c1 c3">MxN</span><span class="c1">&nbsp;</span><span class="c1 c3">&rarr;</span><span class="c1">&nbsp;</span><span class="c1 c3">C[i*N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">j]</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c10"><span class="c0">&#60418;Grid/block formulas used throughout:</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">i</span><span class="c1">&nbsp;</span><span class="c1 c3">=</span><span class="c1">&nbsp;</span><span class="c1 c3">blockIdx.y</span><span class="c1">&nbsp;</span><span class="c1 c3">*</span><span class="c1">&nbsp;</span><span class="c1 c3">blockDim.y</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">threadIdx.y;</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">j</span><span class="c1">&nbsp;</span><span class="c1 c3">=</span><span class="c1">&nbsp;</span><span class="c1 c3">blockIdx.x</span><span class="c1">&nbsp;</span><span class="c1 c3">*</span><span class="c1">&nbsp;</span><span class="c1 c3">blockDim.x</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">threadIdx.x;</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c0">&#60418;</span></p><h2 class="c7" id="h.49sl5j4rwrru"><span class="c2 c18 c11">Rubric Details</span></h2><p class="c10"><span class="c2 c11 c16 c19">Task 1 (10)</span></p><ul class="c15 lst-kix_f1el7cytdyma-0 start"><li class="c5 li-bullet-0"><span class="c0">(4) correct 2D indexing + bounds</span></li><li class="c5 li-bullet-0"><span class="c0">(3) coalesced mapping (x&rarr;cols)</span></li><li class="c5 li-bullet-0"><span class="c0">(3) passes tests, tidy style</span></li></ul><p class="c10"><span class="c2 c11 c16 c19">Task 2 (15)</span></p><ul class="c15 lst-kix_5taui8luwpv-0 start"><li class="c5 li-bullet-0"><span class="c0">(10) correct triple&#8209;loop for arbitrary M,N,K</span></li><li class="c5 li-bullet-0"><span class="c0">(5) clear comments &amp; no UB</span></li></ul><p class="c10"><span class="c2 c11 c16 c19">Task 3 (30)</span></p><ul class="c15 lst-kix_y5hpboojxrq7-0 start"><li class="c5 li-bullet-0"><span class="c0">(10) correct one&#8209;element/thread mapping</span></li><li class="c5 li-bullet-0"><span class="c0">(10) correct launch geometry &amp; bounds</span></li><li class="c5 li-bullet-0"><span class="c0">(5) reasonable performance (scaled timing)</span></li><li class="c5 li-bullet-0"><span class="c0">(5) comments explaining memory pattern</span></li></ul><p class="c10"><span class="c2 c11 c16 c19">Task 4 (30)</span></p><ul class="c15 lst-kix_5db9i5s60gje-0 start"><li class="c5 li-bullet-0"><span class="c0">(12) correct SIMD (V outputs/thread), handles tails</span></li><li class="c5 li-bullet-0"><span class="c0">(8) proper vector loads/stores when aligned</span></li><li class="c5 li-bullet-0"><span class="c0">(5) coalesced writes &amp; justified mapping</span></li><li class="c5 li-bullet-0"><span class="c0">(5) performance better than naive on large sizes</span></li></ul><p class="c10"><span class="c2 c11 c16 c19">Task 5 EC (15)</span></p><ul class="c15 lst-kix_y5uh0mwr7j92-0 start"><li class="c5 li-bullet-0"><span class="c0">(10) measurable speedup over Task 4</span></li><li class="c5 li-bullet-0"><span class="c0">(5) README&#8209;perf.md analysis</span></li></ul><hr><p class="c4 c6"><span class="c0"></span></p><h2 class="c7" id="h.yjsdg1xeia1o"><span class="c2 c18 c11">Appendix A: Minimal Host Launchers (provided in skeleton)</span></h2><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_naive(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">K,</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">block)</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">grid(</span><span class="c1">&nbsp;</span><span class="c1 c3">(N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.x</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.x,</span><span class="c1">&nbsp;</span><span class="c1 c3">(M</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">);</span></p><p class="c4"><span class="c1 c3">mm_naive_kernel&lt;&lt;&lt;grid,</span><span class="c1">&nbsp;</span><span class="c1 c3">block&gt;&gt;&gt;(dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">K);</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_simd(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">K,</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">vec,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">block)</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span></p><p class="c4"><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(vec</span><span class="c1">&nbsp;</span><span class="c1 c3">==</span><span class="c1">&nbsp;</span><span class="c1 c3">4)</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">grid(</span><span class="c1">&nbsp;</span><span class="c1 c3">((N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">3)/4</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.x</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.x,</span></p><p class="c4"><span class="c1 c3">(</span><span class="c1">&nbsp;</span><span class="c1 c3">M</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">);</span></p><p class="c4"><span class="c1 c3">mm_simd_kernel&lt;4&gt;&lt;&lt;&lt;grid,</span><span class="c1">&nbsp;</span><span class="c1 c3">block&gt;&gt;&gt;(dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">K);</span></p><p class="c4"><span class="c1 c3">}</span><span class="c1">&nbsp;</span><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span></p><p class="c4"><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">grid(</span><span class="c1">&nbsp;</span><span class="c1 c3">(N</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.x</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.x,</span><span class="c1">&nbsp;</span><span class="c1 c3">(M</span><span class="c1">&nbsp;</span><span class="c1 c3">+</span><span class="c1">&nbsp;</span><span class="c1 c3">block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">-</span><span class="c1">&nbsp;</span><span class="c1 c3">1)/block.y</span><span class="c1">&nbsp;</span><span class="c1 c3">);</span></p><p class="c4"><span class="c1 c3">mm_naive_kernel&lt;&lt;&lt;grid,</span><span class="c1">&nbsp;</span><span class="c1 c3">block&gt;&gt;&gt;(dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">K);</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c0">&#60418;</span></p><p class="c4"><span class="c2 c11 c16 c19">Appendix B: Starter main.cpp (driver skeleton)</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;cstdio&gt;</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;vector&gt;</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;random&gt;</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;cstring&gt;</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&quot;check.cuh&quot;</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_cpu(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">int,int,int);</span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">copy2D(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">int,int,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3);</span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_naive(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">int,int,int,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3);</span></p><p class="c4"><span class="c1 c3">void</span><span class="c1">&nbsp;</span><span class="c1 c3">mm_simd(const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">const</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">float*,</span><span class="c1">&nbsp;</span><span class="c1 c3">int,int,int,</span><span class="c1">&nbsp;</span><span class="c1 c3">int,</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3);</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">main(int</span><span class="c1">&nbsp;</span><span class="c1 c3">argc,</span><span class="c1">&nbsp;</span><span class="c1 c3">char**</span><span class="c1">&nbsp;</span><span class="c1 c3">argv){</span></p><p class="c4"><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">M=256,N=256,K=256,</span><span class="c1">&nbsp;</span><span class="c1 c3">repeat=5,</span><span class="c1">&nbsp;</span><span class="c1 c3">vec=4;</span><span class="c1">&nbsp;</span><span class="c1 c3">dim3</span><span class="c1">&nbsp;</span><span class="c1 c3">block(16,16);</span></p><p class="c4"><span class="c1 c3">enum</span><span class="c1">&nbsp;</span><span class="c1 c3">{COPY,</span><span class="c1">&nbsp;</span><span class="c1 c3">CPU,</span><span class="c1">&nbsp;</span><span class="c1 c3">NAIVE,</span><span class="c1">&nbsp;</span><span class="c1 c3">SIMD}</span><span class="c1">&nbsp;</span><span class="c1 c3">task</span><span class="c1">&nbsp;</span><span class="c1 c3">=</span><span class="c1">&nbsp;</span><span class="c1 c3">NAIVE;</span></p><p class="c4"><span class="c1 c3">for</span><span class="c1">&nbsp;</span><span class="c1 c3">(int</span><span class="c1">&nbsp;</span><span class="c1 c3">i=1;i&lt;argc;i++){</span></p><p class="c4"><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strncmp(argv[i],&quot;--M=&quot;,4))</span><span class="c1">&nbsp;</span><span class="c1 c3">M=atoi(argv[i]+4);</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strncmp(argv[i],&quot;--N=&quot;,4))</span><span class="c1">&nbsp;</span><span class="c1 c3">N=atoi(argv[i]+4);</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strncmp(argv[i],&quot;--K=&quot;,4))</span><span class="c1">&nbsp;</span><span class="c1 c3">K=atoi(argv[i]+4);</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strncmp(argv[i],&quot;--block=&quot;,8))</span><span class="c1">&nbsp;</span><span class="c1 c3">{</span><span class="c1">&nbsp;</span><span class="c1 c3">int</span><span class="c1">&nbsp;</span><span class="c1 c3">b=atoi(argv[i]+8);</span><span class="c1">&nbsp;</span><span class="c1 c3">block=dim3(b,b);</span><span class="c1">&nbsp;</span><span class="c1 c3">}</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strncmp(argv[i],&quot;--vec=&quot;,6))</span><span class="c1">&nbsp;</span><span class="c1 c3">vec=atoi(argv[i]+6);</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strcmp(argv[i],&quot;--task=copy&quot;))</span><span class="c1">&nbsp;</span><span class="c1 c3">task=COPY;</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strcmp(argv[i],&quot;--task=cpu&quot;))</span><span class="c1">&nbsp;</span><span class="c1 c3">task=CPU;</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strcmp(argv[i],&quot;--task=naive&quot;))</span><span class="c1">&nbsp;</span><span class="c1 c3">task=NAIVE;</span></p><p class="c4"><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(!strcmp(argv[i],&quot;--task=simd&quot;))</span><span class="c1">&nbsp;</span><span class="c1 c3">task=SIMD;</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">std::mt19937</span><span class="c1">&nbsp;</span><span class="c1 c3">gen(42);</span><span class="c1">&nbsp;</span><span class="c1 c3">std::uniform_real_distribution&lt;float&gt;</span><span class="c1">&nbsp;</span><span class="c1 c3">d(-1,1);</span></p><p class="c4"><span class="c1 c3">std::vector&lt;float&gt;</span><span class="c1">&nbsp;</span><span class="c1 c3">hA(M*K),</span><span class="c1">&nbsp;</span><span class="c1 c3">hB(K*N),</span><span class="c1">&nbsp;</span><span class="c1 c3">hC(M*N),</span><span class="c1">&nbsp;</span><span class="c1 c3">hRef(M*N);</span></p><p class="c4"><span class="c1 c3">for</span><span class="c1">&nbsp;</span><span class="c1 c3">(auto&amp;</span><span class="c1">&nbsp;</span><span class="c1 c3">x:</span><span class="c1">&nbsp;</span><span class="c1 c3">hA)</span><span class="c1">&nbsp;</span><span class="c1 c3">x=d(gen);</span><span class="c1">&nbsp;</span><span class="c1 c3">for</span><span class="c1">&nbsp;</span><span class="c1 c3">(auto&amp;</span><span class="c1">&nbsp;</span><span class="c1 c3">x:</span><span class="c1">&nbsp;</span><span class="c1 c3">hB)</span><span class="c1">&nbsp;</span><span class="c1 c3">x=d(gen);</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">float</span><span class="c1">&nbsp;</span><span class="c1 c3">*dA=nullptr,*dB=nullptr,*dC=nullptr;</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMalloc(&amp;dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*K));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMalloc(&amp;dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*K*N));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMalloc(&amp;dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(dA,</span><span class="c1">&nbsp;</span><span class="c1 c3">hA.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*K,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyHostToDevice));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(dB,</span><span class="c1">&nbsp;</span><span class="c1 c3">hB.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*K*N,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyHostToDevice));</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(task==COPY){</span></p><p class="c4"><span class="c1 c3">std::vector&lt;float&gt;</span><span class="c1">&nbsp;</span><span class="c1 c3">tmp(M*N);</span></p><p class="c4"><span class="c1 c3">float</span><span class="c1">&nbsp;</span><span class="c1 c3">*dIn=nullptr,*dOut=nullptr;</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMalloc(&amp;dIn,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMalloc(&amp;dOut,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N));</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(dIn,</span><span class="c1">&nbsp;</span><span class="c1 c3">hA.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyHostToDevice));</span></p><p class="c4"><span class="c1 c3">copy2D(dIn,</span><span class="c1">&nbsp;</span><span class="c1 c3">dOut,</span><span class="c1">&nbsp;</span><span class="c1 c3">M,</span><span class="c1">&nbsp;</span><span class="c1 c3">N,</span><span class="c1">&nbsp;</span><span class="c1 c3">block);</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(tmp.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">dOut,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyDeviceToHost));</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">verify</span><span class="c1">&nbsp;</span><span class="c1 c3">copy</span></p><p class="c4"><span class="c1 c3">}</span><span class="c1">&nbsp;</span><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(task==CPU){</span></p><p class="c4"><span class="c1 c3">mm_cpu(hA.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hB.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hRef.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">M,N,K);</span></p><p class="c4"><span class="c1 c3">}</span><span class="c1">&nbsp;</span><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(task==NAIVE){</span></p><p class="c4"><span class="c1 c3">mm_naive(dA,dB,dC,M,N,K,block);</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(hC.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyDeviceToHost));</span></p><p class="c4"><span class="c1 c3">mm_cpu(hA.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hB.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hRef.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">M,N,K);</span></p><p class="c4"><span class="c1 c3">}</span><span class="c1">&nbsp;</span><span class="c1 c3">else</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">(task==SIMD){</span></p><p class="c4"><span class="c1 c3">mm_simd(dA,dB,dC,M,N,K,vec,block);</span></p><p class="c4"><span class="c1 c3">checkCuda(cudaMemcpy(hC.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">dC,</span><span class="c1">&nbsp;</span><span class="c1 c3">sizeof(float)*M*N,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaMemcpyDeviceToHost));</span></p><p class="c4"><span class="c1 c3">mm_cpu(hA.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hB.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">hRef.data(),</span><span class="c1">&nbsp;</span><span class="c1 c3">M,N,K);</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4"><span class="c1 c3">//</span><span class="c1">&nbsp;</span><span class="c1 c3">compare</span><span class="c1">&nbsp;</span><span class="c1 c3">hC</span><span class="c1">&nbsp;</span><span class="c1 c3">vs</span><span class="c1">&nbsp;</span><span class="c1 c3">hRef</span><span class="c1">&nbsp;</span><span class="c1 c3">if</span><span class="c1">&nbsp;</span><span class="c1 c3">computed</span></p><p class="c4"><span class="c1 c3">return</span><span class="c1">&nbsp;</span><span class="c1 c3">0;</span></p><p class="c4"><span class="c1 c3">}</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span class="c0">&#60418;</span></p><p class="c4"><span class="c2 c11 c16 c19">Appendix C: check.cuh (error helpers)</span></p><p class="c4 c6"><span class="c0"></span></p><p class="c4"><span>&#60419;</span><span class="c1 c3">#pragma</span><span class="c1">&nbsp;</span><span class="c1 c3">once</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;cuda_runtime.h&gt;</span></p><p class="c4"><span class="c1 c3">#include</span><span class="c1">&nbsp;</span><span class="c1 c3">&lt;cstdio&gt;</span></p><p class="c4"><span class="c1 c3">#define</span><span class="c1">&nbsp;</span><span class="c1 c3">checkCuda(call)</span><span class="c1">&nbsp;</span><span class="c1 c3">do{</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaError_t</span><span class="c1">&nbsp;</span><span class="c1 c3">err=(call);</span><span class="c1">&nbsp;</span><span class="c1 c3">if(err!=cudaSuccess){</span><span class="c1">&nbsp;</span><span class="c1 c3">\</span></p><p class="c4"><span class="c1 c3">fprintf(stderr,&quot;CUDA</span><span class="c1">&nbsp;</span><span class="c1 c3">error</span><span class="c1">&nbsp;</span><span class="c1 c3">%s</span><span class="c1">&nbsp;</span><span class="c1 c3">at</span><span class="c1">&nbsp;</span><span class="c1 c3">%s:%d</span></p><p class="c4"><span class="c1 c3">&quot;,</span><span class="c1">&nbsp;</span><span class="c1 c3">cudaGetErrorString(err),</span><span class="c1">&nbsp;</span><span class="c1 c3">__FILE__,</span><span class="c1">&nbsp;</span><span class="c1 c3">__LINE__);</span><span class="c1">&nbsp;</span><span class="c1 c3">\</span></p><p class="c4"><span class="c1 c3">exit(1);}</span><span class="c1">&nbsp;</span><span class="c1 c3">}while(0)</span></p><p class="c4 c6"><span class="c2 c1"></span></p><p class="c4"><span>&#60418;</span></p></body></html>